{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d64a78c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.build_features import get_roast_classification_dataset, get_vocab\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2554e79",
   "metadata": {},
   "source": [
    "# Linear Algorithms\n",
    "\n",
    "* Logistic Regression\n",
    "* Naive Bayes\n",
    "* Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068c5e8e",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "29614540",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_roast_classification_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "58d21fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into test and train datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fce4c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the vocab list from only the TRAINING dataset\n",
    "vocab = get_vocab(X_train, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3f72c0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenizer\n",
    "t = Tokenizer(lower=True, split=' ')\n",
    "# Fit tokenizer only on TRAINING data\n",
    "t.fit_on_texts(vocab)\n",
    "# convert x_train and x_test to count vectors\n",
    "X_train = t.texts_to_matrix(X_train, mode='count')\n",
    "X_test = t.texts_to_matrix(X_test, mode='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6230bd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4492, 1584)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "57e52e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1583"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b302b610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', n_jobs=-1, random_state=27)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since the features are sparse, use L1 regularization.  First start without regularization though.\n",
    "# use balances class_weight since this is an imbalanced classification problem\n",
    "lr_clf = LogisticRegression(class_weight='balanced', random_state=27, n_jobs=-1)\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4e5ed8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4541406945681211"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4613a9",
   "metadata": {},
   "source": [
    "40% of the training examples fall into the medium-light roast class.  This is an imbalanced classification problem.  The logistic regression only does a little better than that baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5f8fe4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.456 regularization parameter C:  0.1\n",
      "accuracy:  0.476 regularization parameter C:  0.2\n",
      "accuracy:  0.484 regularization parameter C:  0.3\n",
      "accuracy:  0.489 regularization parameter C:  0.4\n",
      "accuracy:  0.492 regularization parameter C:  0.5\n",
      "accuracy:  0.501 regularization parameter C:  0.6\n",
      "accuracy:  0.497 regularization parameter C:  0.7\n",
      "accuracy:  0.492 regularization parameter C:  0.8\n",
      "accuracy:  0.492 regularization parameter C:  0.9\n"
     ]
    }
   ],
   "source": [
    "# Try with L1 regularization\n",
    "for c in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    lr_clf = LogisticRegression(penalty='l1', C=c, solver='liblinear', class_weight='balanced', random_state=27)\n",
    "    lr_clf.fit(X_train, y_train)\n",
    "    accuracy = lr_clf.score(X_test, y_test)\n",
    "    print('accuracy: ', round(accuracy, 3), 'regularization parameter C: ', c) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf55934",
   "metadata": {},
   "source": [
    "Best performance is 50% accuracy with a regularization of 0.6.\n",
    "Which features are important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bac9cfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5013357079252003"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit best model\n",
    "lr_clf = LogisticRegression(penalty='l1', C=0.6, solver='liblinear', class_weight='balanced', random_state=27)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d990f64",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6c3b65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_roast_classification_dataset()\n",
    "# Split into test and train datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=23)\n",
    "vocab = get_vocab(X_train, min_count=5)\n",
    "# create tokenizer\n",
    "t = Tokenizer(lower=True, split=' ')\n",
    "# Fit tokenizer only on TRAINING data\n",
    "t.fit_on_texts(vocab)\n",
    "# convert x_train and x_test to count vectors\n",
    "X_train = t.texts_to_matrix(X_train, mode='count')\n",
    "X_test = t.texts_to_matrix(X_test, mode='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "153326f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23686553873552982"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "accuracy_score(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aabeb28",
   "metadata": {},
   "source": [
    "The Naive Bayes model does very poorly.  Random guessing amond 6 classes (if they were equally weighted) would be 17%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e46e660",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "384802b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_roast_classification_dataset()\n",
    "# Split into test and train datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=23)\n",
    "vocab = get_vocab(X_train, min_count=5)\n",
    "# create tokenizer\n",
    "t = Tokenizer(lower=True, split=' ')\n",
    "# Fit tokenizer only on TRAINING data\n",
    "t.fit_on_texts(vocab)\n",
    "# convert x_train and x_test to count vectors\n",
    "X_train = t.texts_to_matrix(X_train, mode='count')\n",
    "X_test = t.texts_to_matrix(X_test, mode='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "59e7c1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4692787177203918"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2574cbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.521 shrinkage regularization parameter:  0.1\n",
      "accuracy:  0.522 shrinkage regularization parameter:  0.2\n",
      "accuracy:  0.516 shrinkage regularization parameter:  0.3\n",
      "accuracy:  0.507 shrinkage regularization parameter:  0.4\n",
      "accuracy:  0.5 shrinkage regularization parameter:  0.5\n",
      "accuracy:  0.491 shrinkage regularization parameter:  0.6\n",
      "accuracy:  0.479 shrinkage regularization parameter:  0.7\n",
      "accuracy:  0.458 shrinkage regularization parameter:  0.8\n",
      "accuracy:  0.441 shrinkage regularization parameter:  0.9\n"
     ]
    }
   ],
   "source": [
    "for param in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    clf = LinearDiscriminantAnalysis(shrinkage=param, solver='eigen')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "    print('accuracy: ', round(accuracy, 3), 'shrinkage regularization parameter: ', param) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2143f09",
   "metadata": {},
   "source": [
    "The LDA without regularization performs about as well as a logistic regression without regularization.  Regularized LDA performs on par with a regularized logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9472b58",
   "metadata": {},
   "source": [
    "## Non-Linear Algorithms\n",
    "\n",
    "* k-nearest neighbors\n",
    "* support vector machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a38a1",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d13dc3e",
   "metadata": {},
   "source": [
    "Surprisingly, this model performs pretty much on par with the LDA and the logistic regression.  Maybe a little bit worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4663e737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_jobs=-1, n_neighbors=6)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=6, n_jobs=-1)\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "815585c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, ..., 2, 2, 1], dtype=int8)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = neigh.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "44110326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46126447016918964"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb2be5a",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036c6440",
   "metadata": {},
   "source": [
    "SVMs are supposed to be effective in high-dimensional spaces. That is promising since my data is in many dimensions.\n",
    "\n",
    "I need to scale my inputs for the SVM so that they have a mean of 0 and a unit variance of 1.  SVM's are not scale invariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "435cb3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4dc2a242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "# Fit only on TRAINING DATA\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ca07bcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7d856379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, class_weight='balanced')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use balanced mode since this is an unbalanced classification model\n",
    "clf = svm.SVC(class_weight='balanced', C=1)\n",
    "clf.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7a060c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, ..., 3, 0, 1], dtype=int8)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_scaled_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b9dd621e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4416740872662511"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
